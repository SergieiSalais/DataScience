{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data in Python (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "\n",
    "- Quick recap\n",
    "- Flat files\n",
    "    - text files\n",
    "- JavaScript Object Notation (JSON)\n",
    "- Importing data from the Web\n",
    "- Working with relational databases in Python    \n",
    "- Importing data from statistical software packages\n",
    "- Q&A\n",
    "    \n",
    "    \n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JavaScript Object Notation (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_json = pd.read_json(\"data/stocks.json\")\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n",
    "\n",
    "df_from_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data from the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V3/main/data/winequality-red.csv'\n",
    "    \n",
    "# Save file locally\n",
    "urlretrieve(url, 'winequality-red.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and reading flat files from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V3/main/data/winequality-red.csv'\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing non-flat files from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V3/main/data/latitude.xls'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "xl = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "# Print the sheetnames \n",
    "print(xl.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xl['1700'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V2/main/data/urbanpop.xlsx'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "xl = pd.read_excel(url, sheet_name=\"1960-1966\")\n",
    "\n",
    "# Print the head of the first sheet \n",
    "xl.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V2/main/data/stocks.json'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "df_from_json = pd.read_json(url)\n",
    "\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n",
    "\n",
    "df_from_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INEGI\n",
    "\n",
    "API del Banco de Indicadores\n",
    "\n",
    "<https://www.inegi.org.mx/servicios/api_indicadores.html>\n",
    "\n",
    "    - Token\n",
    "<https://www.inegi.org.mx/app/desarrolladores/generatoken/Usuarios/token_Verify>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "#https://docs.python.org/3/library/json.html\n",
    "\n",
    "#Llamado al API\n",
    "url='https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/1002000002/es/00000/false/BISE/2.0/32df7fee-ab78-485a-828f-9e3370a1ee63?type=json'\n",
    "response= requests.get(url)\n",
    "\n",
    "if response.status_code==200:\n",
    "    content= json.loads(response.content)\n",
    "    \n",
    "content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener datos de la serie histórica del indicador de Población total, en los Estados Unidos Mexicanos, en idioma español, en formato JSON y calcular su promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "#Llamado al API\n",
    "url='https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/1002000002/es/00000/false/BISE/2.0/32df7fee-ab78-485a-828f-9e3370a1ee63?type=json'\n",
    "response= requests.get(url)\n",
    "if response.status_code==200:\n",
    "    content= json.loads(response.content)\n",
    "    Series=content['Series'][0]['OBSERVATIONS']   \n",
    "    \n",
    "    #Obtención de la lista de observaciones \n",
    "    Observaciones=[]\n",
    "    for obs in Series:  Observaciones.append(float(obs['OBS_VALUE']));\n",
    "    \n",
    "\n",
    "    #Generación del promedio de la lista de observaciones \n",
    "    sum=0.0\n",
    "    for i in range(0,len(Observaciones)): sum=sum+Observaciones[i];  \n",
    "\n",
    "    resultado=sum/len(Observaciones);\n",
    "    print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Worl Bank\n",
    "\n",
    "Developer Information\n",
    "\n",
    "<https://datahelpdesk.worldbank.org/knowledgebase/topics/125589>\n",
    "\n",
    "WBGAPI\n",
    "\n",
    "<https://pypi.org/project/wbgapi/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a basic data query that returns a single indicator for all available economies and 5 even years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wbgapi as wb   \n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wb.data.DataFrame('SP.POP.TOTL', time=range(2010, 2020, 1), labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of per-capita income for 2 countries and 2 decades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.data.DataFrame('NY.GDP.PCAP.CD', [ 'MEX', 'COL'],\n",
    "                  range(2000, 2021), index='time').plot(figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos Abiertos\n",
    "\n",
    "México\n",
    "\n",
    "<https://datos.gob.mx/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "#Llamado al API\n",
    "url='https://api.datos.gob.mx/v1/datasets/'\n",
    "response= requests.get(url)\n",
    "\n",
    "if response.status_code==200:\n",
    "    content= json.loads(response.content)\n",
    "    \n",
    "content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia API\n",
    "\n",
    "The MediaWiki Action API is a web service that allows access to some wiki-features like authentication, page operations, and search. It can provide meta information about the wiki and the logged-in user.\n",
    "\n",
    "- Data science\n",
    "    - From Wikipedia, the free encyclopedia\n",
    "    \n",
    "https://en.wikipedia.org/wiki/Data_science#:~:text=Data%20science%20is%20an%20interdisciplinary,broad%20range%20of%20application%20domains.\n",
    "\n",
    "- EndPoint   \n",
    "\n",
    "<https://www.mediawiki.org/wiki/API:Main_page>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=data%20science'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "#json_data\n",
    "\n",
    "ds_data = json_data['query']['pages']['35458904']['extract']\n",
    "\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with relational databases in Python\n",
    "\n",
    "Relational databases, an essential element of any data scientist's toolkit. \n",
    "\n",
    "You will be learning about the relational model, creating SQL queries, filtering and ordering your SQL records, and advanced querying by JOINing database tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a database engine\n",
    "\n",
    "- Chinook Database\n",
    "\n",
    "\n",
    "> The name of this sample database was based on the Northwind database. Chinooks are winds in the interior West of North America, where the Canadian Prairies and Great Plains meet various mountain ranges. Chinooks are most prevalent over southern Alberta in Canada. Chinook is a good name choice for a database that intends to be an alternative to Northwind.\n",
    "\n",
    "- DB   \n",
    "\n",
    "    - <https://github.com/lerocha/chinook-database>\n",
    "\n",
    "- Engine\n",
    "\n",
    "    - <https://docs.sqlalchemy.org/en/14/core/engines.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sqlalchemy\n",
    "\n",
    "# https://pypi.org/project/SQLAlchemy/\n",
    "\n",
    "# https://docs.sqlalchemy.org/en/14/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(sqlite:///data/Chinook.sqlite)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary module\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///data/Chinook.sqlite')\n",
    "\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the tables in the database?\n",
    "\n",
    "Before you can get any data out of the database,  you'll need to know what tables it contains!\n",
    "\n",
    "To this end, you'll save the table names to a list using the method table_names() on the engine and then you will print the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/mgr4w2nj1y54f_qb92pw19hh0000gp/T/ipykernel_6711/1617455427.py:2: SADeprecationWarning: The Engine.table_names() method is deprecated and will be removed in a future release.  Please refer to Inspector.get_table_names(). (deprecated since: 1.4)\n",
      "  table_names = engine.table_names()\n"
     ]
    }
   ],
   "source": [
    "# Save the table names to a list: table_names\n",
    "table_names = engine.table_names()\n",
    "\n",
    "# Print the table names to the shell\n",
    "print(table_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/Chinook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hello World of SQL Queries!\n",
    "\n",
    "In this section you'll perform the Hello World of SQL queries, SELECT, in order to retrieve all columns of the table Album in the Chinook database. Recall that the query SELECT * selects all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Luís</td>\n",
       "      <td>Gonçalves</td>\n",
       "      <td>Embraer - Empresa Brasileira de Aeronáutica S.A.</td>\n",
       "      <td>Av. Brigadeiro Faria Lima, 2170</td>\n",
       "      <td>São José dos Campos</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>12227-000</td>\n",
       "      <td>+55 (12) 3923-5555</td>\n",
       "      <td>+55 (12) 3923-5566</td>\n",
       "      <td>luisg@embraer.com.br</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Leonie</td>\n",
       "      <td>Köhler</td>\n",
       "      <td>None</td>\n",
       "      <td>Theodor-Heuss-Straße 34</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>None</td>\n",
       "      <td>Germany</td>\n",
       "      <td>70174</td>\n",
       "      <td>+49 0711 2842222</td>\n",
       "      <td>None</td>\n",
       "      <td>leonekohler@surfeu.de</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>François</td>\n",
       "      <td>Tremblay</td>\n",
       "      <td>None</td>\n",
       "      <td>1498 rue Bélanger</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>QC</td>\n",
       "      <td>Canada</td>\n",
       "      <td>H2G 1A7</td>\n",
       "      <td>+1 (514) 721-4711</td>\n",
       "      <td>None</td>\n",
       "      <td>ftremblay@gmail.com</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bjørn</td>\n",
       "      <td>Hansen</td>\n",
       "      <td>None</td>\n",
       "      <td>Ullevålsveien 14</td>\n",
       "      <td>Oslo</td>\n",
       "      <td>None</td>\n",
       "      <td>Norway</td>\n",
       "      <td>0171</td>\n",
       "      <td>+47 22 44 22 22</td>\n",
       "      <td>None</td>\n",
       "      <td>bjorn.hansen@yahoo.no</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>František</td>\n",
       "      <td>Wichterlová</td>\n",
       "      <td>JetBrains s.r.o.</td>\n",
       "      <td>Klanova 9/506</td>\n",
       "      <td>Prague</td>\n",
       "      <td>None</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>14700</td>\n",
       "      <td>+420 2 4172 5555</td>\n",
       "      <td>+420 2 4172 5555</td>\n",
       "      <td>frantisekw@jetbrains.com</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1            2   \\\n",
       "0   1       Luís    Gonçalves   \n",
       "1   2     Leonie       Köhler   \n",
       "2   3   François     Tremblay   \n",
       "3   4      Bjørn       Hansen   \n",
       "4   5  František  Wichterlová   \n",
       "\n",
       "                                                 3   \\\n",
       "0  Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
       "1                                              None   \n",
       "2                                              None   \n",
       "3                                              None   \n",
       "4                                  JetBrains s.r.o.   \n",
       "\n",
       "                                4                    5     6               7   \\\n",
       "0  Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP          Brazil   \n",
       "1          Theodor-Heuss-Straße 34            Stuttgart  None         Germany   \n",
       "2                1498 rue Bélanger             Montréal    QC          Canada   \n",
       "3                 Ullevålsveien 14                 Oslo  None          Norway   \n",
       "4                    Klanova 9/506               Prague  None  Czech Republic   \n",
       "\n",
       "          8                   9                   10  \\\n",
       "0  12227-000  +55 (12) 3923-5555  +55 (12) 3923-5566   \n",
       "1      70174    +49 0711 2842222                None   \n",
       "2    H2G 1A7   +1 (514) 721-4711                None   \n",
       "3       0171     +47 22 44 22 22                None   \n",
       "4      14700    +420 2 4172 5555    +420 2 4172 5555   \n",
       "\n",
       "                         11  12  \n",
       "0      luisg@embraer.com.br   3  \n",
       "1     leonekohler@surfeu.de   5  \n",
       "2       ftremblay@gmail.com   3  \n",
       "3     bjorn.hansen@yahoo.no   4  \n",
       "4  frantisekw@jetbrains.com   4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///data/Chinook.sqlite')\n",
    "\n",
    "# Open engine connection\n",
    "con = engine.connect()\n",
    "\n",
    "# Perform query: rs\n",
    "rs = con.execute(\"SELECT * FROM Customer\")\n",
    "\n",
    "# Save results of the query to DataFrame: df\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "# Close connection\n",
    "con.close()\n",
    "\n",
    "# Print head of DataFrame df\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing from other formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing R data\n",
    "\n",
    "<https://github.com/ofajardo/pyreadr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PyreadrError",
     "evalue": "File b'data/weather.rds' does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPyreadrError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zj/mgr4w2nj1y54f_qb92pw19hh0000gp/T/ipykernel_6711/3945606431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyreadr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyreadr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/weather.rds'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# also works for RData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# extract the pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyreadr/pyreadr.py\u001b[0m in \u001b[0;36mread_r\u001b[0;34m(path, use_objects, timezone)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfilename_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPyreadrError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File {0} does not exist!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPyreadrError\u001b[0m: File b'data/weather.rds' does not exist!"
     ]
    }
   ],
   "source": [
    "import pyreadr\n",
    "\n",
    "data = pyreadr.read_r('data/weather.rds') # also works for RData\n",
    "\n",
    "df = data[None] # extract the pandas data frame \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing SAS files\n",
    "\n",
    "- <https://www.sas.com/en_us/home.html>\n",
    "\n",
    "- <https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/hostwin/n0sk6o15955yoen19n9ghdziqw1u.htm#p0sgui0b1o9nljn1crwkx9k7yr4w>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>181.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>250.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>265.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>248.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR     P           S\n",
       "0  1950.0  12.9  181.899994\n",
       "1  1951.0  11.9  245.000000\n",
       "2  1952.0  10.7  250.199997\n",
       "3  1953.0  11.3  265.899994\n",
       "4  1954.0  11.2  248.500000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install sas7bdat\n",
    "\n",
    "# Import sas7bdat package\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Save file to a DataFrame: df_sas\n",
    "with SAS7BDAT('data/sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "# Print head of DataFrame\n",
    "df_sas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_sas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Stata files\n",
    "\n",
    "<https://www.stata.com/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wbcode</th>\n",
       "      <th>country</th>\n",
       "      <th>disa1</th>\n",
       "      <th>disa2</th>\n",
       "      <th>disa3</th>\n",
       "      <th>disa4</th>\n",
       "      <th>disa5</th>\n",
       "      <th>disa6</th>\n",
       "      <th>disa7</th>\n",
       "      <th>disa8</th>\n",
       "      <th>...</th>\n",
       "      <th>disa16</th>\n",
       "      <th>disa17</th>\n",
       "      <th>disa18</th>\n",
       "      <th>disa19</th>\n",
       "      <th>disa20</th>\n",
       "      <th>disa21</th>\n",
       "      <th>disa22</th>\n",
       "      <th>disa23</th>\n",
       "      <th>disa24</th>\n",
       "      <th>disa25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  wbcode               country  disa1  disa2  disa3  disa4  disa5  disa6  \\\n",
       "0    AFG           Afghanistan   0.00   0.00   0.76   0.73    0.0   0.00   \n",
       "1    AGO                Angola   0.32   0.02   0.56   0.00    0.0   0.00   \n",
       "2    ALB               Albania   0.00   0.00   0.02   0.00    0.0   0.00   \n",
       "3    ARE  United Arab Emirates   0.00   0.00   0.00   0.00    0.0   0.00   \n",
       "4    ARG             Argentina   0.00   0.24   0.24   0.00    0.0   0.23   \n",
       "\n",
       "   disa7  disa8  ...  disa16  disa17  disa18  disa19  disa20  disa21  disa22  \\\n",
       "0   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "1   0.56    0.0  ...     0.0     0.4     0.0    0.61    0.00     0.0    0.99   \n",
       "2   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "3   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.00     0.0    0.00   \n",
       "4   0.00    0.0  ...     0.0     0.0     0.0    0.00    0.05     0.0    0.00   \n",
       "\n",
       "   disa23  disa24  disa25  \n",
       "0    0.02    0.00    0.00  \n",
       "1    0.98    0.61    0.00  \n",
       "2    0.00    0.00    0.16  \n",
       "3    0.00    0.00    0.00  \n",
       "4    0.01    0.00    0.11  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Stata file into a pandas DataFrame: df\n",
    "df = pd.read_stata('data/disarea.dta')\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using h5py to import HDF5 files\n",
    "\n",
    "<https://www.hdfgroup.org/solutions/hdf5/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h5py._hl.files.File"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'data/L-L1_LOSC_4_V1-1126259446-32.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file, 'r')\n",
    "\n",
    "# Print the datatype of the loaded file\n",
    "type(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta\n",
      "quality\n",
      "strain\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the file\n",
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MatLab (.mat) files\n",
    "\n",
    "<https://www.mathworks.com/products/matlab.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import scipy.io\n",
    "\n",
    "# Load MATLAB file: mat\n",
    "mat = scipy.io.loadmat('data/albeck_gene_expression.mat')\n",
    "#mat = scipy.io.loadmat('data/ja_data2.mat')\n",
    "\n",
    "# Print the datatype type of mat\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'rfpCyt', 'rfpNuc', 'cfpNuc', 'cfpCyt', 'yfpNuc', 'yfpCyt', 'CYratioCyt'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the keys of the MATLAB dictionary\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
    "print(type(mat['CYratioCyt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 137)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
    "print(np.shape(mat['CYratioCyt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45452828, 1.45565564, 1.44976855, 1.43462701, 1.42254717,\n",
       "       1.41797674, 1.27794176, 1.22593573, 1.16828719, 1.16563016,\n",
       "       1.17690634, 1.32351316, 1.43087562, 1.4608052 , 1.44118846,\n",
       "       1.2576108 , 1.17416244, 1.16500043, 1.17600378, 1.21088682,\n",
       "       1.26816583, 1.38275979, 1.38356258, 1.30697631, 1.17082168,\n",
       "       1.17959836, 1.18968628, 1.2042729 , 1.2801658 , 1.37007579,\n",
       "       1.33207307, 1.20997379, 1.15286206, 1.16269752, 1.17707873,\n",
       "       1.21696135, 1.30454232, 1.35457108, 1.33429957, 1.1791073 ,\n",
       "       1.1748539 , 1.18732482, 1.20002222, 1.23357194, 1.29627093,\n",
       "       1.32857357, 1.31347809, 1.18643201, 1.17360083, 1.17568763,\n",
       "       1.19057057, 1.2182355 , 1.27304043, 1.29324679, 1.1960901 ,\n",
       "       1.18671497, 1.18027266, 1.1824329 , 1.20047195, 1.24622775,\n",
       "       1.27208085, 1.18666067, 1.18637573, 1.18980102, 1.19297631,\n",
       "       1.21255691, 1.24163487, 1.18189666, 1.18010695, 1.17607704,\n",
       "       1.1900533 , 1.20572485, 1.1963422 , 1.17998771, 1.18143463,\n",
       "       1.18210659, 1.18692618, 1.19563625, 1.16885728, 1.15693302,\n",
       "       1.15550353, 1.15701578, 1.16672046, 1.18196457, 1.1762444 ,\n",
       "       1.1649777 , 1.15402063, 1.15876959, 1.17501199, 1.16032713,\n",
       "       1.17221627, 1.15635806, 1.16130115, 1.16013687, 1.16324754,\n",
       "       1.16283201, 1.15699833, 1.15590066, 1.1610204 , 1.1558139 ,\n",
       "       1.15124473, 1.14920157, 1.15136429, 1.14847934, 1.14761864,\n",
       "       1.15012932, 1.1493494 , 1.15126692, 1.1567748 , 1.15253366,\n",
       "       1.13841338, 1.13876136, 1.1425189 , 1.14030179, 1.13752593,\n",
       "       1.13614891, 1.13716882, 1.14244408, 1.14175206, 1.13485217,\n",
       "       1.13442175, 1.13962363, 1.13930553, 1.13447325, 1.1292516 ,\n",
       "       1.13303496, 1.1282534 , 1.12461091, 1.13797497, 1.13988672,\n",
       "       1.13624193, 1.13215043])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Subset the array and plot it\n",
    "data = mat['CYratioCyt'][25, 5:]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "PyreadstatError",
     "evalue": "File data/person.sav does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPyreadstatError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zj/mgr4w2nj1y54f_qb92pw19hh0000gp/T/ipykernel_6711/2137636493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyreadstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_spss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/person.sav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# https://github.com/Roche/pyreadstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/spss.py\u001b[0m in \u001b[0;36mread_spss\u001b[0;34m(path, usecols, convert_categoricals)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pyreadstat requires a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     df, _ = pyreadstat.read_sav(\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_value_formats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_categoricals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     )\n",
      "\u001b[0;32mpyreadstat/pyreadstat.pyx\u001b[0m in \u001b[0;36mpyreadstat.pyreadstat.read_sav\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpyreadstat/_readstat_parser.pyx\u001b[0m in \u001b[0;36mpyreadstat._readstat_parser.run_conversion\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPyreadstatError\u001b[0m: File data/person.sav does not exist!"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "df = pd.read_spss(\"data/person.sav\")\n",
    "\n",
    "# https://github.com/Roche/pyreadstat\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Google Drive/PhD/Software/Python/Code/CienciaDatos_Python/Importing Data in Python (Part 1).ipynb",
    "public": false
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.788px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "568.85px",
    "left": "1283px",
    "right": "20px",
    "top": "120px",
    "width": "337px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
